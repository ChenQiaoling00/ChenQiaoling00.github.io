{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "CxWYlaUAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Qiaoling Chen", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CxWYlaUAAAAJ&citpid=3", "affiliation": "Nanyang Technology University", "organization": 3012140508424117850, "interests": [], "email_domain": "@ntu.edu.sg", "homepage": "https://chenqiaoling00.github.io/", "citedby": 193, "publications": {"CxWYlaUAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Characterization of large language model development in the datacenter", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:u-x6o8ySG0sC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2628672474394944772", "cites_id": ["2628672474394944772"]}, "CxWYlaUAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Loongtrain: Efficient training of long-sequence llms with head-context parallelism", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:UeHWp8X0CEIC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11045317929417969480", "cites_id": ["11045317929417969480"]}, "CxWYlaUAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hydro:{Surrogate-Based} hyperparameter tuning service in datacenters", "pub_year": "2023"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:d1gkVwhDpl0C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13900495196875169293", "cites_id": ["13900495196875169293"]}, "CxWYlaUAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Internevo: Efficient long-sequence large language model training via hybrid parallelism and redundant sharding", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:2osOgNQ5qMEC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6517574022967835170", "cites_id": ["6517574022967835170"]}, "CxWYlaUAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lins: Reducing communication overhead of ZeRo for efficient LLM training", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:qjMakFHDy7sC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9310499802781643720,4347983307328699382,6417304941904474316", "cites_id": ["9310499802781643720", "4347983307328699382", "6417304941904474316"]}, "CxWYlaUAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SPPO: Efficient Long-sequence LLM Training via Adaptive Sequence Pipeline Parallel Offloading", "pub_year": "2025"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:eQOLeE2rZwMC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18015522248298295861", "cites_id": ["18015522248298295861"]}, "CxWYlaUAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Expert-as-a-Service: Towards Efficient, Scalable, and Robust Large-scale MoE Serving", "pub_year": "2025"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:WF5omc3nYNoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13545955924592879288", "cites_id": ["13545955924592879288"]}, "CxWYlaUAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems", "pub_year": "2025"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:ufrVoPGSRksC", "num_citations": 0}}, "citedby5y": 193, "hindex": 5, "hindex5y": 5, "i10index": 5, "i10index5y": 5, "cites_per_year": {"2023": 3, "2024": 54, "2025": 136}, "updated": "2025-12-02 08:22:07.529887"}