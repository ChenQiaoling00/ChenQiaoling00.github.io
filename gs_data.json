{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "CxWYlaUAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Qiaoling Chen", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CxWYlaUAAAAJ&citpid=3", "affiliation": "Nanyang Technology University", "organization": 3012140508424117850, "interests": [], "email_domain": "@ntu.edu.sg", "homepage": "https://chenqiaoling00.github.io/", "citedby": 175, "publications": {"CxWYlaUAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Characterization of large language model development in the datacenter", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:u-x6o8ySG0sC", "num_citations": 102, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2628672474394944772", "cites_id": ["2628672474394944772"]}, "CxWYlaUAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Loongtrain: Efficient training of long-sequence llms with head-context parallelism", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:UeHWp8X0CEIC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11045317929417969480", "cites_id": ["11045317929417969480"]}, "CxWYlaUAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hydro:{Surrogate-Based} hyperparameter tuning service in datacenters", "pub_year": "2023"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:d1gkVwhDpl0C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13900495196875169293", "cites_id": ["13900495196875169293"]}, "CxWYlaUAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Internevo: Efficient long-sequence large language model training via hybrid parallelism and redundant sharding", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:2osOgNQ5qMEC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6517574022967835170", "cites_id": ["6517574022967835170"]}, "CxWYlaUAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lins: Reducing communication overhead of ZeRo for efficient LLM training", "pub_year": "2024"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:qjMakFHDy7sC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4347983307328699382,9310499802781643720,6417304941904474316", "cites_id": ["4347983307328699382", "9310499802781643720", "6417304941904474316"]}, "CxWYlaUAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SPPO: Efficient Long-sequence LLM Training via Adaptive Sequence Pipeline Parallel Offloading", "pub_year": "2025"}, "filled": false, "author_pub_id": "CxWYlaUAAAAJ:eQOLeE2rZwMC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18015522248298295861", "cites_id": ["18015522248298295861"]}}, "citedby5y": 175, "hindex": 5, "hindex5y": 5, "i10index": 5, "i10index5y": 5, "cites_per_year": {"2023": 3, "2024": 55, "2025": 117}, "updated": "2025-10-30 08:18:51.363200"}